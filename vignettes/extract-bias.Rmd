---
title: "{epiparameter} Extraction Bias Analysis"
output: 
  bookdown::html_vignette2:
    fig_caption: yes
vignette: >
  %\VignetteIndexEntry{{epiparameter} Extraction Bias Analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 5,
  fig.align = 'center'
)
```

::: {.alert .alert-info}
If you are unfamiliar with the parameter extraction functionality in {epiparameter} 
the Conversion and Extraction vignette is a great place to start.
:::

The {epiparameter} R package contains a set of functions to extract parameters
of probability distributions given a set of summary statistics. These summary statistics can
be the values at given percentiles of a distribution, or the median and range of
a data set to which a distribution can be fit. Using these and specifying the distribution 
(e.g. gamma, lognormal, etc.) the parameters of the distribution can be extracted by 
optimisation using least-squares.

The precision and bias of this approach needs to be explored across the parameter space
of the different distributions to understand potential erroneous inferences. This
vignette aims to explore this inference bias for the three distribution currently 
supported in {epiparameter} for parameter extraction: gamma, lognormal and weibull.

::: {.alert .alert-warning}
This is not an in depth analysis of the estimation methods implemented in {epiparameter}, 
but rather a supplementary article exploring the bias and consistency of the functions.
It is specific to the case of {epiparameter} and should not be taken as a generalised results.
:::

```{r setup}
library(epiparameter)
library(ggplot2)
```

## Extraction Bias

### Extraction by percentiles

First we explore extraction from percentiles.

If a study reports the percentiles of a distribution, they are usually symmetrical
(e.g. 5th and 95th, or 2.5th and 97.5th). However, in a few instances, only asymmetrical
percentiles are available. We test whether asymetry to varying degrees influences the
precision of parameter extraction for all distributions.

We set up the parameter space to explore:

```{r, set-up-parameter-space-percentiles}
distributions <- c("gamma", "lnorm", "weibull")
dist_parameters <- seq(0.5, 2, 0.5)
lower_percentiles <- c(2.5, 5, 25, 40)
upper_percentiles <- c(60, 95, 97.5)

parameters_perc <- expand.grid(
  dist = distributions, 
  param_1 = dist_parameters, 
  param_2 = dist_parameters, 
  lower = lower_percentiles, 
  upper = upper_percentiles
)

# calculate the degree of asymmetry for each percentile combination
lw_interval_diff <- abs(0 - parameters_perc$lower)
up_interval_diff <- abs(100 - parameters_perc$upper)
deg_asym <- abs(lw_interval_diff - up_interval_diff)

# add degree of asymmetry to percentiles
parameters_perc <- cbind(parameters_perc, deg_asym)

# divide percentiles by 100 to make them probabilities for quantile functions
parameters_perc$lower <- parameters_perc$lower / 100
parameters_perc$upper <- parameters_perc$upper / 100
```

Now we can run the extraction for each point in parameter space. We set a seed
to control for stochasticity when estimating the parameters, however changing or
removing the seed should not drastically change the results or interpretation.

```{r, set-seed}
set.seed(1)
```

```{r, run-extraction-percentile}
estim_params <- vector("list", nrow(parameters_perc))
# Loop through parameter space estimating parameters
for (params_idx in seq_len(nrow(parameters_perc))) {
  
  dist <- as.character(parameters_perc[params_idx, "dist"])
  percen <- unname(unlist(parameters_perc[params_idx, c("lower", "upper")]))
  
  if (dist == "lnorm") {
    true_values <- do.call(
      paste0("q", dist),
      list(
        p = percen,
        meanlog = parameters_perc[params_idx, "param_1"],
        sdlog = parameters_perc[params_idx, "param_2"]
      )
    )
  } else {
    true_values <- do.call(
      paste0("q", dist),
      list(
        p = percen,
        shape = parameters_perc[params_idx, "param_1"],
        scale = parameters_perc[params_idx, "param_2"]
      )
    )
  }
  
  # message about stochastic optimisation suppressed
  estim_params[[params_idx]] <- suppressMessages(
    extract_param(
      type = "percentiles",
      values = true_values,
      distribution = dist,
      percentiles = percen,
      control = list(tolerance = 10)
    )
  )
}

# combine results
results <- cbind(parameters_perc, do.call(rbind, estim_params))

colnames(results) <- c(
  "dist", "param_1", "param_2", "lower", "upper", 
  "deg_asym", "estim_param_1", "estim_param_2"
)  

# calculate absolute difference between true parameter and estimated value
results <- cbind(
  results, 
  diff_param_1 = abs(results$param_1 - results$estim_param_1),
  diff_param_2 = abs(results$param_2 - results$estim_param_2)
)
```

In the above code chunk the `extract_param()` function re-runs the optimisation
until convergence to a set tolerance is achieved to more reliably return the global 
optimum. For this analysis we set the tolerance to be arbitrarily large (i.e. 10) 
to meet the convergence criteria immediately in order to save computation time. Therefore
these results may be more biased than if the function were run with the default tolerance
(`1e-5`).

The extraction precision/bias can be explored:

```{r, plot-results-percentiles, fig.cap="Parameter estimation bias facetted by distribution. Parameter 1 is either the shape parameter, for gamma and weibull distributions, or meanlog for the lognormal distribution. Parameter 2 is either the scale parameter for gamma and weibull distributions, or sdlog for the lognormal distribution."}
# plot differences by distribution
ggplot(data = results) +
  geom_point(mapping = aes(
    x = diff_param_1, 
    y = diff_param_2, 
    colour = deg_asym
  )) + 
  scale_x_continuous(name = "Parameter 1 Difference (|true - estimated|)") +
  scale_y_continuous(name = "Parameter 2 Difference (|true - estimated|)") +
  labs(colour = "Percentile Asym.") + 
  theme_bw() +
  scale_color_viridis_c() +
  facet_wrap(facets = vars(dist), scales = "free") +
  theme(strip.background = element_blank())
```

### Extraction by median and range

The same analysis as above can be repeated, this time using the other summary
statistic possibly reported in studies: an inferred distribution's median and range.
For this extraction the number of samples used to infer the distribution is required
as this can impact the possible range exhibited by the data.

Set up the parameter space:

```{r, set-up-parameter-space-med-range}
n_samples <- c(10, 50, 100)
parameters_range <- expand.grid(
  dist = distributions, # same as above
  param_1 = dist_parameters, # same as above
  param_2 = dist_parameters, # same as above
  n_samples = n_samples
)
```

```{r run-extraction-med-range}
estim_params <- vector("list", nrow(parameters_range))
# Loop through parameter space estimating parameters
for (params_idx in seq_len(nrow(parameters_range))) {
  
  dist <- as.character(parameters_range[params_idx, "dist"])
  n_samples <- parameters_range[params_idx, "n_samples"]
  
  if (dist == "lnorm") {
    true_median <- do.call(
      paste0("q", dist),
      list(
        p = 0.5,
        meanlog = parameters_range[params_idx, "param_1"],
        sdlog = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- do.call(
      paste0("r", dist),
      list(
        n = n_samples,
        meanlog = parameters_range[params_idx, "param_1"],
        sdlog = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- c(min(true_range), max(true_range))
  } else {
    true_median <- do.call(
      paste0("q", dist),
      list(
        p = 0.5,
        shape = parameters_range[params_idx, "param_1"],
        scale = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- do.call(
      paste0("r", dist),
      list(
        n = n_samples,
        shape = parameters_range[params_idx, "param_1"],
        scale = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- c(min(true_range), max(true_range))
  }
  
  true_values <- c(true_median, true_range)
  
  # message about stochastic optimisation suppressed
  estim_params[[params_idx]] <- suppressMessages(
    expr =  extract_param(
      type = "range",
      values = true_values,
      distribution = dist,
      samples = n_samples,
      control = list(tolerance = 10)
    )
  )
}

# combine results
results <- cbind(parameters_range, do.call(rbind, estim_params))

colnames(results) <- c(
  "dist", "param_1", "param_2", "n_samples", "estim_param_1", "estim_param_2"
)

# calculate absolute difference between true parameter and estimated value
results <- cbind(
  results, 
  diff_param_1 = abs(results$param_1 - results$estim_param_1),
  diff_param_2 = abs(results$param_2 - results$estim_param_2)
)
```

Plot results:

```{r, plot-results-med-range, fig.cap="Parameter extraction bias. Parameter 1 is either the shape parameter, for gamma and weibull distributions, or meanlog for the lognormal distribution. Parameter 2 is either the scale parameter for gamma and weibull distributions, or sdlog for the lognormal distribution."}
# plot differences by distribution
ggplot(data = results) +
  geom_point(
    mapping = aes(
      x = diff_param_1, 
      y = diff_param_2, 
      colour = n_samples
    )
  ) +
  scale_x_continuous(name = "Parameter 1 Difference (|true - estimated|)") +
  scale_y_continuous(name = "Parameter 2 Difference (|true - estimated|)") +
  labs(colour = "No. Samples") + 
  theme_bw() +
  scale_color_viridis_c() + 
  facet_wrap(facets = vars(dist), scales = "free") +
  theme(strip.background = element_blank())

```

## Extraction stability

### Extraction by percentiles

The two analyses above used a single extraction (replicate), however, it may be that
the estimation of the parameters is unstable for a given set of percentiles or median 
range. Therefore, we finish with a test of whether repeated extraction of parameters 
from a single percentile has large variance which would indicate the parameter extraction
is unstable and potentially untrustworthy.

We use the same parameter space for percentiles as defined above 
(`parameters_perc`). Now we can run the extraction for a set of replicates to 
compute the variance of parameter estimates over those replicates.

```{r, run-extraction-stability-percentile}
estim_param_var <- vector("list", nrow(parameters_perc))
# Loop through parameter space estimating parameters
for (params_idx in seq_len(nrow(parameters_perc))) {
  
  dist <- as.character(parameters_perc[params_idx, "dist"])
  percen <- unname(unlist(parameters_perc[params_idx, c("lower", "upper")]))
  
  if (dist == "lnorm") {
    true_values <- do.call(
      paste0("q", dist),
      list(
        p = percen,
        meanlog = parameters_perc[params_idx, "param_1"],
        sdlog = parameters_perc[params_idx, "param_2"]
      )
    )
  } else {
    true_values <- do.call(
      paste0("q", dist),
      list(
        p = percen,
        shape = parameters_perc[params_idx, "param_1"],
        scale = parameters_perc[params_idx, "param_2"]
      )
    )
  }
  
  # message about stochastic optimisation suppressed
  estim <- suppressMessages(
    replicate(
      n = 5,
      expr =  extract_param(
        type = "percentiles",
        values = true_values,
        distribution = dist,
        percentiles = percen,
        control = list(tolerance = 10)
      )
    )
  )
  estim_param_var[[params_idx]] <- apply(estim, MARGIN = 1, FUN = var)
}

# combine results
results <- cbind(parameters_perc, do.call(rbind, estim_param_var))

colnames(results) <- c(
  "dist", "param_1", "param_2", "lower", "upper", 
  "deg_asym", "estim_param_1_var", "estim_param_2_var"
)  
```

```{r, plot-results, fig.cap="Parameter extraction stability, facetted by distribution. Parameter 1 is either the shape parameter, for gamma and weibull distributions, or meanlog for the lognormal distribution. Parameter 2 is either the scale parameter for gamma and weibull distributions, or sdlog for the lognormal distribution."}
ggplot(data = results) +
  geom_point(mapping = aes(
    x = estim_param_1_var, 
    y = estim_param_2_var, 
    colour = deg_asym
  )) + 
  scale_x_continuous(name = "Parameter 1 Variance") +
  scale_y_continuous(name = "Parameter 2 Variance") +
  labs(colour = "Percentile Asym.") + 
  theme_bw() +
  scale_color_viridis_c() + 
  facet_wrap(facets = vars(dist), scales = "free") +
  theme(strip.background = element_blank())
```

### Extraction by median and range

The same test of estimation consistency can be performed for the extraction from median and range.


```{r, run-extraction-stability-range}
estim_param_var <- vector("list", nrow(parameters_range))
# Loop through parameter space estimating parameters
for (params_idx in seq_len(nrow(parameters_range))) {
  
  dist <- as.character(parameters_range[params_idx, "dist"])
  n_samples <- parameters_range[params_idx, "n_samples"]
  
  if (dist == "lnorm") {
    true_median <- do.call(
      paste0("q", dist),
      list(
        p = 0.5,
        meanlog = parameters_range[params_idx, "param_1"],
        sdlog = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- do.call(
      paste0("r", dist),
      list(
        n = n_samples,
        meanlog = parameters_range[params_idx, "param_1"],
        sdlog = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- c(min(true_range), max(true_range))
  } else {
    true_median <- do.call(
      paste0("q", dist),
      list(
        p = 0.5,
        shape = parameters_range[params_idx, "param_1"],
        scale = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- do.call(
      paste0("r", dist),
      list(
        n = n_samples,
        shape = parameters_range[params_idx, "param_1"],
        scale = parameters_range[params_idx, "param_2"]
      )
    )
    true_range <- c(min(true_range), max(true_range))
  }
  
  true_values <- c(true_median, true_range)
  
  # message about stochastic optimisation suppressed
  estim <- suppressMessages(
    replicate(
      n = 5,
      expr =  extract_param(
        type = "range",
        values = true_values,
        distribution = dist,
        samples = n_samples,
        control = list(tolerance = 10)
      )
    )
  )
  estim_param_var[[params_idx]] <- apply(estim, MARGIN = 1, FUN = var)
}

# combine results
results <- cbind(parameters_range, do.call(rbind, estim_param_var))

colnames(results) <- c(
  "dist", "param_1", "param_2", "n_samples", "estim_param_1_var", 
  "estim_param_2_var"
)  
```

```{r, plot-estim-var-range, fig.cap="Parameter extraction stability, facetted by distribution. Parameter 1 is either the shape parameter, for gamma and weibull distributions, or meanlog for the lognormal distribution. Parameter 2 is either the scale parameter for gamma and weibull distributions, or sdlog for the lognormal distribution."}
ggplot(data = results) +
  geom_point(mapping = aes(
    x = estim_param_1_var, 
    y = estim_param_2_var, 
    colour = n_samples
  )) + 
  scale_x_continuous(name = "Parameter 1 Variance") +
  scale_y_continuous(name = "Parameter 2 Variance") +
  labs(colour = "No. Samples") + 
  theme_bw() +
  scale_color_viridis_c() + 
  facet_wrap(facets = vars(dist), scales = "free") +
  theme(strip.background = element_blank())
```
